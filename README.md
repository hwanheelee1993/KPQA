# KPQA

This repository provides an evaluation metric for generative question answering systems based on our paper [KPQA: A Metric for Generative Question Answering Using Keyphrase Weights](https://arxiv.org/abs/2005.00192).
We provide the code to train KPQA, pretrained model, human annotated data and the code to compute KPQA-metric.

<h2> Usage </h2>

<h3> 1. Install Prerequisites </h3>
Install packages using "requirements.txt"

<h3> 2. Download Pretrained Model </h3>
We provide the pre-trained KPQA model in the following link. (TBD)

<h3> 3. Compute Metric </h3>
You can compute KPQA-metric using "compute_correlation.py"

<h3> Train KPQA (optional) </h3>
You can train your own KPQA model using the provided dataset or your own dataset using "train.py".
